{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SOURCE_URL = 'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "FILENAME = SOURCE_URL.split('/')[-1]\n",
    "DATA_DIR = './datasets'\n",
    "\n",
    "def maybe_download(data_dir):\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    if not os.path.isfile(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading {} {:.1f} %'.format(\n",
    "                FILENAME, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully donloaded', FILENAME, statinfo.st_size, 'bytes.')\n",
    "\n",
    "def load(data_dir, subset='train'):\n",
    "    maybe_download(data_dir)\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    \n",
    "    f = gzip.open(filepath, 'rb')\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    train_set, valid_set, test_set = u.load()\n",
    "    f.close()\n",
    "    \n",
    "    if subset == 'train':\n",
    "        trainx, trainy = train_set\n",
    "        trainx = trainx.astype(np.float32).reshape(trainx.shape[0], 28, 28)\n",
    "        trainy = trainy.astype(np.uint8)\n",
    "        return trainx, trainy\n",
    "    elif subset == 'test':\n",
    "        testx, testy = test_set\n",
    "        testx = testx.astype(np.float32).reshape(testx.shape[0], 28, 28)\n",
    "        testy = testy.astype(np.uint8)\n",
    "        return testx, testy\n",
    "    elif subset== 'valid':\n",
    "        validx, validy = valid_set\n",
    "        validx = validx.astype(np.float32).reshape(validx.shape[0], 28, 28)\n",
    "        validy = validy.astype(np.uint8)\n",
    "        return validx, validy\n",
    "    else:\n",
    "        raise NotImplementedError('subset should be train or valid or test')\n",
    "\n",
    "# Load data\n",
    "train_data, train_label = load(DATA_DIR, 'train')\n",
    "valid_data, valid_label = load(DATA_DIR, 'valid')\n",
    "test_data, test_label = load(DATA_DIR, 'test')\n",
    "\n",
    "# concatenate train and valid data as train data\n",
    "train_data = np.concatenate((train_data, valid_data))\n",
    "train_label = np.concatenate((train_label, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 확인 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[100]\n",
    "ax1.imshow(sample_data, cmap=plt.cm.Greys);\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "num_display = 100\n",
    "\n",
    "def get_model(X, by, is_reuse):\n",
    "    X = tf.expand_dims(X, axis=3) # (None, 28, 28, 1)\n",
    "    \n",
    "    with tf.variable_scope('first'):\n",
    "        outs = tf.layers.conv2d(X, 128, 3, padding='same', name='conv1', reuse = tf.AUTO_REUSE) # (None, 28, 28, 128)\n",
    "        outs = tf.layers.batch_normalization(outs)\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2) # (None, 14, 14, 128)\n",
    "    with tf.variable_scope('second'):\n",
    "        outs = tf.layers.conv2d(outs, 256, 3, padding='same', name='conv2', reuse = is_reuse)\n",
    "        outs = tf.layers.batch_normalization(outs)\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2) # (None, 7, 7, 256)\n",
    "    with tf.variable_scope('third'):\n",
    "        outs = tf.layers.conv2d(outs, 64, 3, padding='same', name='conv3', reuse = is_reuse)\n",
    "        outs = tf.layers.batch_normalization(outs)\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2) # (None, 3, 3, 64)\n",
    "    outs = tf.reshape(outs, (-1, outs.shape[1]*outs.shape[2]*outs.shape[3]))\n",
    "    with tf.variable_scope('dense'):\n",
    "        outs = tf.layers.dense(outs, 128, name='dense1', reuse=is_reuse)\n",
    "        outs = tf.nn.relu(outs)\n",
    "#        outs = tf.layers.dropout(outs, rate = 0.5)\n",
    "        outs = tf.layers.dense(outs, 10, name='dense2', reuse= is_reuse)\n",
    "    one_hot = tf.one_hot(by, 10)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=outs, \n",
    "                                                      labels=one_hot)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    preds = tf.cast(tf.argmax(tf.nn.softmax(outs), axis=1), tf.int32)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(by, preds), tf.float32))\n",
    "    saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'second')\n",
    "                          + tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'third')\n",
    "                           + tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'dense')\n",
    "                          )\n",
    "    \n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    return {\n",
    "        'loss': loss,\n",
    "        'opt': opt,\n",
    "        'preds': preds,\n",
    "        'acc': acc,\n",
    "        'init': init,\n",
    "        'saver' : saver\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 28, 28))\n",
    "by = tf.placeholder(tf.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n",
      "loss 2.3008 acc 0.1200\n",
      "loss 2.2882 acc 0.1200\n",
      "loss 2.2899 acc 0.1300\n",
      "loss 2.2848 acc 0.2100\n",
      "loss 2.2773 acc 0.3500\n",
      "loss 2.2847 acc 0.2500\n",
      "Current iteration 2\n",
      "loss 2.2677 acc 0.3200\n",
      "loss 2.2594 acc 0.3500\n",
      "loss 2.2627 acc 0.3200\n",
      "loss 2.2603 acc 0.3300\n",
      "loss 2.2436 acc 0.3800\n",
      "loss 2.2550 acc 0.2800\n"
     ]
    }
   ],
   "source": [
    "model = get_model(X, by, False)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(model['init'])\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch + 1))\n",
    "        \n",
    "        for ind_ in range(0, int(60000 / batch_size)):\n",
    "            batch_X = train_data[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = train_label[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            _, cur_loss, cur_acc = sess.run(\n",
    "                [model['opt'], model['loss'], model['acc']],\n",
    "                feed_dict={X: batch_X, by: batch_by})\n",
    "            if ind_ % num_display == 0:\n",
    "                print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    model['saver'].save(sess, './ours.ckpt')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable first/batch_normalization/gamma already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-b6d98528c41d>\", line 11, in get_model\n    outs = tf.layers.batch_normalization(outs)\n  File \"<ipython-input-7-06c0c2d9c5c7>\", line 1, in <module>\n    model = get_model(X, by, False)\n  File \"/home/pirl/anaconda3/envs/TM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8db7fe5ee3b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'saver'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./ours.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b6d98528c41d>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(X, by, is_reuse)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO_REUSE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (None, 28, 28, 128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (None, 14, 14, 128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(inputs, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, training, trainable, name, reuse, renorm, renorm_clipping, renorm_momentum, fused, virtual_batch_size, adjustment)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m       _scope=name)\n\u001b[0;32m--> 309\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \"\"\"\n\u001b[0;32m--> 817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_set_learning_phase_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m           \u001b[0;31m# the user has manually overwritten the build method do we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0;31m# build it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    280\u001b[0m           \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m           trainable=True)\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             getter=vs.get_variable)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    610\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    637\u001b[0m     new_variable = getter(\n\u001b[1;32m    638\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TM/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    859\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 861\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    862\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable first/batch_normalization/gamma already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-b6d98528c41d>\", line 11, in get_model\n    outs = tf.layers.batch_normalization(outs)\n  File \"<ipython-input-7-06c0c2d9c5c7>\", line 1, in <module>\n    model = get_model(X, by, False)\n  File \"/home/pirl/anaconda3/envs/TM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "model = get_model(X, by, True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(model['init'])\n",
    "    model['saver'].restore(sess, './ours.ckpt')\n",
    "    \n",
    "    cur_acc_all = 0.0\n",
    "    cur_loss_all = 0.0\n",
    "    for ind_ in range(0, 10):\n",
    "        cur_loss, cur_acc = sess.run(\n",
    "                    [model['loss'], model['acc']],\n",
    "                    feed_dict={X: test_data[ind_*1000:(ind_+1)*1000], \n",
    "                               by: test_label[ind_*1000:(ind_+1)*1000]})\n",
    "        cur_loss_all += cur_loss\n",
    "        cur_acc_all += cur_acc\n",
    "    print('TEST: loss {0:.4f} acc {1:.4f}'.format(cur_loss_all / 10.0, \n",
    "                                                  cur_acc_all / 10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM",
   "language": "python",
   "name": "tm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
